library(Hmisc)  ## use the describe command
library(mfx)
library(jtools)
opts_chunk$set(echo = TRUE)
options(digits = 3)
#opts_knit$set(root.dir ="C:/Users/baileyma/Documents/Textbook/OUP/Supplementals_Jan2019/Supplementals_July2019/Labs_R")
## As needed, set path to folder where data is located.
## For example: opts_knit$set(root.dir ="C:/Data")
dta <- read_dta("Ch12_Lab_Titanic.dta")    # Load data
dta$pclass_2 <- (dta$pclass == 2)
dta$pclass_3 <- (dta$pclass == 3)
lab12_a <- lm(formula = survived~pclass_2+pclass_3, data = dta)
jtools::summ(lab12_a)
#Create different single-category variables as necessary
dta$female = (dta$sex == "female")
dta$child = (dta$age < 17)
dta$Queensland = (dta$embarked == "Q")
dta$Cherbourg = (dta$embarked == "C")
#Run the model
lab12_b <- lm(survived ~ pclass_2+pclass_3+female+child+Queensland + Cherbourg + age, data = dta)
#Output results
jtools::summ(lab12_b)
#Create different single-category variables as necessary
dta$female = (dta$sex == "female")
dta$child = (dta$age < 17)
dta$Queensland = (dta$embarked == "Q")
dta$Cherbourg = (dta$embarked == "C")
#Run the model
lab12_b <- lm(survived ~ pclass_2+pclass_3+female+child+Queensland + Cherbourg + age, data = dta)
#Output results
jtools::summ(lab12_b)
#Calculate predicted values
lab12_b_pred <- predict(lab12_b)
min(lab12_b_pred)
max(lab12_b_pred)
id <- names(lab12_b_pred[lab12_b_pred == min(lab12_b_pred)])
dta$name[as.numeric(id)]
#Find the ID for the person with the lowest probability of surviving.
id <- names(lab12_b_pred[lab12_b_pred == min(lab12_b_pred)])
dta$name[as.numeric(id)]
dta$age[as.numeric(id)]
dta$sex[as.numeric(id)]
dta$pclass[as.numeric(id)]
#Same as before but with max instead of min
id <- names(lab12_b_pred[lab12_b_pred == max(lab12_b_pred)])
dta$name[as.numeric(id)]
dta$age[as.numeric(id)]
dta$sex[as.numeric(id)]
dta$pclass[as.numeric(id)]
lab12_f = glm(formula = survived~pclass_2+pclass_3, data = dta, family = binomial(link = 'probit'))
jtools::summ(lab12_f)
#First estimate the model
lab12_g = glm(formula = survived~pclass_2+pclass_3+age+female+child+Queensland+Cherbourg, data = dta, family = binomial(link = 'probit'))
#Then find the predicted values
lab12_g_pred <- predict(lab12_g)
#Then output the min and max
min(lab12_g_pred)
max(lab12_g_pred)
#First estimate the model
lab12_g = glm(formula = survived~pclass_2+pclass_3+age+female+child+Queensland+Cherbourg, data = dta, family = binomial(link = 'probit'))
#Then find the predicted values
lab12_g_pred <- predict(lab12_g, type = 'response')
#Then output the min and max
min(lab12_g_pred)
max(lab12_g_pred)
id <- names(lab12_g_pred[lab12_g_pred == min(lab12_g_pred)])
dta$name[as.numeric(id)]
P1 = pnorm(coef(lab12_g)[1] + coef(lab12_g)[2] *dta$pclass_2+ coef(lab12_g)[3]*dta$pclass_3            + coef(lab12_g)[4]*dta$age + coef(lab12_g)[5] *dta$female + coef(lab12_g)[6]*dta$child + coef(lab12_g)[7]*dta$Queensland + coef(lab12_g)[8] *dta$Cherbourg)
P2 = pnorm(coef(lab12_g)[1] + coef(lab12_g)[2] *dta$pclass_2+ coef(lab12_g)[3]*dta$pclass_3            + coef(lab12_g)[4]*(dta$age+1) + coef(lab12_g)[5] *dta$female + coef(lab12_g)[6]*dta$child + coef(lab12_g)[7]*dta$Queensland + coef(lab12_g)[8] *dta$Cherbourg)
diff = P2 - P1
mean(diff)
P1 = pnorm(coef(lab12_g)[1] + coef(lab12_g)[2] *dta$pclass_2+ coef(lab12_g)[3]*dta$pclass_3            + coef(lab12_g)[4]*dta$age + coef(lab12_g)[5] *dta$female + coef(lab12_g)[6]*dta$child + coef(lab12_g)[7]*dta$Queensland + coef(lab12_g)[8] *dta$Cherbourg)
P2 = pnorm(coef(lab12_g)[1] + coef(lab12_g)[2] *dta$pclass_2+ coef(lab12_g)[3]*dta$pclass_3            + coef(lab12_g)[4]*(dta$age+1) + coef(lab12_g)[5] *dta$female + coef(lab12_g)[6]*dta$child + coef(lab12_g)[7]*dta$Queensland + coef(lab12_g)[8] *dta$Cherbourg)
diff = P2 - P1
mean(diff, na.rm = TRUE)
require(knitr)
require(haven)  ## install.packages("haven")
require(car)    ## install.packages("car")
require(AER)    ## install.packages("AER")
library(Hmisc)  ## use the describe command
library(mfx)
library(jtools)
opts_chunk$set(echo = TRUE)
options(digits = 5)
#opts_knit$set(root.dir ="C:/Users/baileyma/Documents/Textbook/OUP/Supplementals_Jan2019/Supplementals_July2019/Labs_R")
## As needed, set path to folder where data is located.
## For example: opts_knit$set(root.dir ="C:/Data")
rm(list = ls(all = TRUE))   # Remove objects from the previous session
## setwd("/Users/baileyma/Documents/Teaching/PPOL560/PPOL560_data")
dta <- read_dta("Ch12_Lab_Titanic.dta")    # Load data
dta$pclass_2 <- (dta$pclass == 2)
dta$pclass_3 <- (dta$pclass == 3)
lab12_a <- lm(formula = survived~pclass_2+pclass_3, data = dta)
jtools::summ(lab12_a)
#Create different single-category variables as necessary
dta$female = (dta$sex == "female")
dta$child = (dta$age < 17)
dta$Queensland = (dta$embarked == "Q")
dta$Cherbourg = (dta$embarked == "C")
#Run the model
lab12_b <- lm(survived ~ pclass_2+pclass_3+female+child+Queensland + Cherbourg + age, data = dta)
#Output results
jtools::summ(lab12_b)
#Create different single-category variables as necessary
dta$female = (dta$sex == "female")
dta$child = (dta$age < 17)
dta$Queensland = (dta$embarked == "Q")
dta$Cherbourg = (dta$embarked == "C")
#Run the model
lab12_b <- lm(survived ~ pclass_2+pclass_3+female+child+Queensland + Cherbourg + age, data = dta)
#Output results
summary(lab12_b)
probitmfx(lab12_g, data = dta, atmean = FALSE)
#Calculate predicted values
lab12_b_pred <- predict(lab12_b)
min(lab12_b_pred)
max(lab12_b_pred)
#Find the ID for the person with the lowest probability of surviving.
id <- names(lab12_b_pred[lab12_b_pred == min(lab12_b_pred)])
dta$name[as.numeric(id)]
dta$age[as.numeric(id)]
dta$sex[as.numeric(id)]
dta$pclass[as.numeric(id)]
#Same as before but with max instead of min
id <- names(lab12_b_pred[lab12_b_pred == max(lab12_b_pred)])
dta$name[as.numeric(id)]
dta$age[as.numeric(id)]
dta$sex[as.numeric(id)]
dta$pclass[as.numeric(id)]
#Estimate the model
lab12_f = glm(formula = survived~pclass_2+pclass_3, data = dta, family = binomial(link = 'probit'))
#Output the results
jtools::summ(lab12_f)
#First estimate the model
lab12_g = glm(formula = survived~pclass_2+pclass_3+age+female+child+Queensland+Cherbourg, data = dta, family = binomial(link = 'probit'))
#Then find the predicted values
lab12_g_pred <- predict(lab12_g, type = 'response')
#Then output the min and max
min(lab12_g_pred)
max(lab12_g_pred)
id <- names(lab12_g_pred[lab12_g_pred == min(lab12_g_pred)])
dta$name[as.numeric(id)]
#First, generate predictions based on the data as is
P1 = pnorm(coef(lab12_g)[1] + coef(lab12_g)[2] *dta$pclass_2+ coef(lab12_g)[3]*dta$pclass_3 + coef(lab12_g)[4]*dta$age + coef(lab12_g)[5] *dta$female + coef(lab12_g)[6]*dta$child + coef(lab12_g)[7]*dta$Queensland + coef(lab12_g)[8] *dta$Cherbourg)
#Next generate predictions when 1 is added to age
P2 = pnorm(coef(lab12_g)[1] + coef(lab12_g)[2] *dta$pclass_2+ coef(lab12_g)[3]*dta$pclass_3 + coef(lab12_g)[4]*(dta$age+1) + coef(lab12_g)[5] *dta$female + coef(lab12_g)[6]*dta$child + coef(lab12_g)[7]*dta$Queensland + coef(lab12_g)[8] *dta$Cherbourg)
#Find the mean difference between the two predictions
diff = P2 - P1
mean(diff, na.rm = TRUE)
probitmfx(lab12_g, data = dta, atmean = FALSE)
dta <- read_dta("Ch12_Lab_Titanic.dta")    # Load data
dta$pclass_2 <- (dta$pclass == 2)
dta$pclass_3 <- (dta$pclass == 3)
lab12_a <- lm(formula = survived~pclass_2+pclass_3, data = dta)
summary(lab12_a)
# Load packages used in this session of R
library(knitr)
library(here)
library(dplyr)
library(mfx)
opts_chunk$set(echo = TRUE)
options(digits = 2)
c_codes <- read.csv("Country_codes_for_WVS_wave_7.csv")
wvs <- read.csv("WV7_small.csv")
#Rename the column to facilitate the join
c_codes <- c_codes %>%
rename(
B_COUNTRY = V2
)
#Merge the two data frames
wvs <- merge(c_codes, wvs, by = 'B_COUNTRY', all = TRUE)
#If a country was recorded in this data set, there would be a survey year for it.
#wvs_Y records the rows where Survey Year is not NA, while wvs_N records the rows where it is
wvs_Y <- subset(wvs, !is.na(wvs$SurveyYear))
wvs_N <- subset(wvs, is.na(wvs$SurveyYear))
#Print the first ten countries which do appear in the world values data
head(unique(wvs_Y$country), 10)
#Print the first ten countries which do not appear in the world values data
head(unique(wvs_N$country), 10)
#Let's write a function!
#Define the function
satisfaction_by_gender <- function(country_name){
#Include an if clause in case the country does not have data
if (!is.element(country_name, unique(wvs_Y$country))){
print(paste0("I'm sorry, I can't find data for ", country_name, " based on the records available. Please recall the 'satisfaction_by_gender' function on a different country name."))
}
#Define a new data frame with only the data for the requested country
else{
df <- wvs_Y %>% filter(country == country_name)
#Define a data frame slice with just the country data for men
df_M <- df %>% filter(Male == 1)
#Define another slice with just the country data for women
df_F <- df %>% filter(Male == 0)
#Output the results
print(paste0("This edition of the World Values Survey gathered data from ", country_name, '.'))
print(paste0('The responses collected include ', nrow(df_M), ' men and ', nrow(df_F), ' women.'))
print(paste0("The men surveyed in ", country_name, " reported an average satisfaction of ", mean(df_M$Satisfied, na.rm = TRUE), ' out of 10, and the women surveyed in ', country_name, ' reported an average satisfaction of ', mean(df_F$Satisfied, na.rm = TRUE), ' out of 10.'))
}
}
#Test with randomly generated country names
satisfaction_by_gender('Andorra')
satisfaction_by_gender('Mongolia')
satisfaction_by_gender('United States')
#First I want to see the distribution of the immigrant variable
#table(wvs_Y$Immigrant)
length(unique(wvs_Y$country))
#Let's write a function!
immigrant_percent <- function(){
#Since for immigrant, 1 = no and 2 = yes, by subtracting 1 from the variable, I end up with 0 = no and 1 = yes, which is much easier to work with.
wvs_Y$Immigrant <- wvs_Y$Immigrant - 1
#Create a new empty vector for country names
country_list <- character(length = length(unique(wvs_Y$country)))
#Copy each unique country name to the vector of country names
country_list <- unique(wvs_Y$country)
#Create a new empty vector for immigrant percent
immig_100 <- character()
#Iterate through the unique country values
for (ii in unique(wvs_Y$country)){
#filter for just the rows which match each country
df <- wvs_Y %>% filter(wvs_Y$country == ii)
#Calculate the mean immigrant value
x <- mean(df$Immigrant, na.rm = TRUE)
#Append that value to the immigrant percent vector
immig_100 <- c(immig_100, x)
}
#Bind the two vectors together
immig_percent <-cbind(country_list, immig_100)
#Convert the bound vectors to a data frame
immig_percent <- data.frame(immig_percent)
#Return the data frame
return(immig_percent)
}
#Store the output as a data frame
immigrant_percent_df <- immigrant_percent()
#Order it in ascending order by percentage of survey respondents who are immigrants
immigrant_percent_df <- immigrant_percent_df[order(immigrant_percent_df$immig_100),]
#Print the 10 countries with the smallest proportions of immigrants
head(immigrant_percent_df$country_list, 10)
#Print the 10 countries with the largest proportions of immigrants
tail(immigrant_percent_df$country_list, 10)
#I ended up using a lot of code from my answer to question 4 to answer this question.
#Let's write a function!
immigrant_men <- function(){
#Since for immigrant, 1 = no and 2 = yes, by subtracting 1 from the variable, I end up with 0 = no and 1 = yes, which is much easier to work with.
wvs_Y$Immigrant <- wvs_Y$Immigrant - 1
#Create a new empty vector for country names
country_list <- character(length = length(unique(wvs_Y$country)))
#Copy each unique country name to the vector of country names
country_list <- unique(wvs_Y$country)
#Create a new empty vector for immigrant percent
immig_men <- character()
#Iterate through the unique country values
for (ii in unique(wvs_Y$country)){
#filter for just the rows which match each country
df <- wvs_Y %>% filter(country == ii) %>% filter(Immigrant == 1)
#Calculate the mean immigrant value
x <- mean(df$Male, na.rm = TRUE)
#Append that value to the immigrant percent vector
immig_men <- c(immig_men, x)
}
#Bind the two vectors together
immig_man100 <-cbind(country_list, immig_men)
#Convert the bound vectors to a data frame
immig_man100 <- data.frame(immig_man100)
#Sort by ascending order of percentage of immigrants who are men
immig_man100 <- immig_man100[order(immig_man100$immig_men),]
#Return the data frame
return(immig_man100)
}
#Store the function output as a data frame
immigrant_men_df <- immigrant_men()
#Report the 10 countries with the smallest percentages of male immigrants
head(immigrant_men_df$country_list, 10)
#Report the 10 countries with the largest percentages of male immigrants
tail(immigrant_men_df$country_list, 10)
male_marital <- function(country_name){
#Include an if clause in case the country does not have data
if (!is.element(country_name, unique(wvs_Y$country))){
print(paste0("I'm sorry, I can't find data for ", country_name, " based on the records available. Please recall the 'male_marital' function on a different country name."))
}
else{
#Create a data frame slice for just the male respondents from the requested country
df <- wvs_Y %>% filter(country == country_name) %>% filter(Male == 1)
print(paste0("Here are the statistics for the marital status of male respondents from ", country_name, ":"))
print(paste0(nrow(subset(df, Marital == 1))/nrow(df)*100, "% of male respondents in ", country_name, " are married."))
print(paste0(nrow(subset(df, Marital == 2))/nrow(df)*100, "% of male respondents in ", country_name, " are living together as married."))
print(paste0(nrow(subset(df, Marital == 3))/nrow(df)*100, "% of male respondents in ", country_name, " are divorced."))
print(paste0(nrow(subset(df, Marital == 4))/nrow(df)*100, "% of male respondents in ", country_name, " are separated."))
print(paste0(nrow(subset(df, Marital == 5))/nrow(df)*100, "% of male respondents in ", country_name, " are widowed."))
print(paste0(nrow(subset(df, Marital == 6))/nrow(df)*100, "% of male respondents in ", country_name, " are single."))
print('To see information for another country, please call the male_marital function and specify your requested country name. Thank you!')
}
}
#Test with randomly generated country names
male_marital('Saudi Arabia')
male_marital('Peru')
#Create a new binary variable where 1 = divorced or separated and 0 = not
wvs_Y$divorced <- ifelse(wvs_Y$Marital == 3,1,0)
wvs_Y$divorced <- ifelse(wvs_Y$Marital == 4,1,wvs_Y$divorced)
#Filter the data by my chosen country
df <- wvs_Y %>% filter(country == 'Peru')
#Estimate lpm, probit, and logit models
linprob <- lm(formula = divorced ~ Income+Education+Male+Age, data = df)
summary(linprob)
prob <- glm(formula = divorced ~ Income+Education+Male+Age, data = df, family = binomial(link = 'probit'))
summary(prob)
log_model <- glm(formula = divorced ~ Income+Education+Male+Age, data = df, family = binomial(link = 'logit'))
summary(log_model)
#Filter the data by my chosen country
df1 <- wvs_Y %>% filter(country == 'Andorra')
prob1 <- glm(formula = divorced ~ Income+Education+Male+Age, data = df1, family = binomial(link = 'probit'))
#Get the marginal effects for Peru
probitmfx(prob, data = wvs_Y, atmean = FALSE)
#Get the marginal effects for Andorra
probitmfx(prob1, data = wvs_Y, atmean = FALSE)
#Create a new binary variable where 1 = divorced or separated and 0 = not
wvs_Y$divorced <- ifelse(wvs_Y$Marital == 3,1,0)
wvs_Y$divorced <- ifelse(wvs_Y$Marital == 4,1,wvs_Y$divorced)
#Filter the data by my chosen country
df <- wvs_Y %>% filter(country == 'Peru')
#Estimate lpm, probit, and logit models
linprob <- lm(formula = divorced ~ Income+Education+Male+Age, data = df)
summary(linprob)
prob_peru <- glm(formula = divorced ~ Income+Education+Male+Age, data = df, family = binomial(link = 'probit'))
summary(prob)
log_model <- glm(formula = divorced ~ Income+Education+Male+Age, data = df, family = binomial(link = 'logit'))
summary(log_model)
#Filter the data by my chosen country
df1 <- wvs_Y %>% filter(country == 'Andorra')
prob_andorra <- glm(formula = divorced ~ Income+Education+Male+Age, data = df1, family = binomial(link = 'probit'))
#Get the marginal effects for Peru
probitmfx(prob_peru, data = wvs_Y, atmean = FALSE)
#Get the marginal effects for Andorra
probitmfx(prob_andorra, data = wvs_Y, atmean = FALSE)
View(df)
View(df1)
shiny::runApp('C:/Users/alexi/Desktop/data_visualizations/Personal_projects/COVID_County_USA')
shiny::runApp('C:/Users/alexi/Desktop/data_visualizations/Personal_projects/COVID_County_USA')
library(shiny)
library(readr)
library(ggplot2)
library(dplyr)
library(png)
library(cairoDevice)
library(Cairo)
library(tigris)
options(bitmapType='cairo')
options(tigris_use_cache = TRUE)
#Import covid deaths spreadsheet
urlfile = "https://raw.githubusercontent.com/nytimes/covid-19-data/master/us.csv"
c19data = read.csv(url(urlfile))
#Import county population data
#counties = readRDS('counties.rds')
#countydata = read.csv('countydata1.csv')
countydata1$FIPS = sprintf("%05d", as.numeric(countydata1$FIPS))
justfips = countydata1[,c('FIPS', 'TOT_POP')]
justfips = justfips %>% rename(fips = FIPS)
countydata = read.csv('countydata1.csv')
countydata1$FIPS = sprintf("%05d", as.numeric(countydata1$FIPS))
justfips = countydata1[,c('FIPS', 'TOT_POP')]
justfips = justfips %>% rename(fips = FIPS)
countydata1 = read.csv('countydata1.csv')
countydata1 = read.csv('countydata1.csv')
setwd("C:/Users/alexi/Desktop/data_visualizations/Personal_projects/COVID_County_USA")
countydata1 = read.csv('countydata1.csv')
countydata1$FIPS = sprintf("%05d", as.numeric(countydata1$FIPS))
justfips = countydata1[,c('FIPS', 'TOT_POP')]
justfips = justfips %>% rename(fips = FIPS)
countyshapes = counties()
countyshapes = geo_join(countyshapes, justfips, 'GEOID', 'fips', how = 'inner')
runApp()
runApp('version control 1.R')
runApp('version control 1.R')
options(repr.plot.width = 12, repr.plot.height = 8)
runApp('version control 1.R')
runApp('version control.R')
runApp('version control 1.R')
runApp('version control 1.R')
runApp('version control 1.R')
runApp('version control 1.R')
runApp('version control 1.R')
runApp('version control 1.R')
runApp('version control 1.R')
runApp('version control 1.R')
counties = readRDS('counties.rds')
View(counties)
write.csv(counties, 'counties_incomplete.csv')
counties = read.csv('counties.csv')
View(counties)
runApp('version control.R')
runApp('version control.R')
runApp('version control 1.R')
runApp('version control 1.R')
runApp('version control 1.R')
runApp('version control 1.R')
runApp('version control 1.R')
runApp('version control 1.R')
runApp('version control 1.R')
runApp('version control 1.R')
runApp('version control 1.R')
runApp('version control 1.R')
runApp('version control 1.R')
runApp('version control 1.R')
runApp('version control 1.R')
runApp('version control 1.R')
View(justfips)
runApp('version control 1.R')
runApp('version control 1.R')
runApp('version control 1.R')
runApp('version control 1.R')
runApp('version control 1.R')
runApp('version control 1.R')
runApp('version control 1.R')
View(c19data)
runApp('version control 1.R')
runApp('version control 1.R')
runApp('version control 1.R')
runApp('version control 1.R')
runApp('version control 1.R')
runApp('version control 1.R')
runApp('version control 1.R')
runApp('version control 1.R')
runApp('version control 1.R')
runApp('version control 1.R')
runApp('version control 1.R')
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
View(countydata1)
countydata2 = read.csv('countydata1.csv')
countydata1 = read.csv('countydata1.csv')
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runGitHub('https://github.com/aadams149/data_visualizations/tree/main/Personal_projects/COVID_County_USA', 'aadams149')
runGitHub('aadams149/data_visualizations/tree/main/Personal_projects/COVID_County_USA', 'aadams149')
runGitHub('data_visualizations', 'aadams149', subdir = 'Personal_projects/COVID_County_USA')
runGitHub('data_visualizations', 'aadams149', subdir = 'tree/main/Personal_projects/COVID_County_USA')
runGitHub('data_visualizations', 'aadams149', subdir = 'tree/main/Personal_projects/')
runGitHub('data_visualizations', 'aadams149', subdir = 'tree/main/Personal_projects/COVID_County_USA')
runGitHub('data_visualizations', 'aadams149', subdir = 'tree/main/Personal_projects/COVID_County_USA.zip')
runGitHub('data_visualizations', 'aadams149', subdir = 'Personal_projects/COVID_County_USA.zip')
runUrl('https://github.com/aadams149/data_visualizations/blob/main/Personal_projects/COVID_County_USA.zip')
runUrl('https://github.com/aadams149/data_visualizations/blob/main/Personal_projects/COVID_County_USA')
runUrl('https://github.com/aadams149/data_visualizations/blob/main/Personal_projects/COVID_County_USA/')
runGitHub('data_visualizations', 'aadams149', subdir = 'Personal_projects/COVID_County_USA/')
runURL('https://github.com/aadams149/data_visualizations/blob/main/Personal_projects/COVID_County_USA.zip')
library(shiny)
runURL('https://github.com/aadams149/data_visualizations/blob/main/Personal_projects/COVID_County_USA.zip')
runUrl('https://github.com/aadams149/data_visualizations/blob/main/Personal_projects/COVID_County_USA.zip')
install.packages('rsconnect')
rsconnect::setAccountInfo(name='aadams149', token='88C6E1CFE0BF9459631C5E97C1DB249A', secret='xRmfaOC/QIp9hDgKg2GfuzMo6F0u4vVPy62XPPpm')
setwd("C:/Users/alexi/Desktop/data_visualizations/Personal_projects/COVID_County_USA")
rsconnect::deployApp(appFiles = c('app.R', 'countydata1.csv'), appName = 'COVID County, USA', launch.browser = TRUE)
rsconnect::deployApp(appFiles = c('app.R', 'countydata1.csv'), appName = 'COVID_County_USA', launch.browser = TRUE)
rsconnect::deployApp()
runApp()
rsconnect::deployApp()
sessionInfo()
rsconnect::deployApp()
sessionInfo()
library(shiny)
library(readr)
library(ggplot2)
library(dplyr)
library(usmap)
library(png)
library(Cairo)
rsconnect::deployApp()
